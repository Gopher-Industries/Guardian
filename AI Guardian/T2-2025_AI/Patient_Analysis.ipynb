{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1qfsk9oR_Ml9Upkbgje8qEKyX8w78SulLiJZ9UIbL0PI/export?format=csv\"\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load Data from CSV\n",
    "# -----------------------------\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(sheet_url)\n",
    "    # Convert timestamps if present\n",
    "    if \"observationStart\" in df.columns:\n",
    "        df[\"observationStart\"] = pd.to_datetime(df[\"observationStart\"])\n",
    "    if \"observationEnd\" in df.columns:\n",
    "        df[\"observationEnd\"] = pd.to_datetime(df[\"observationEnd\"])\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# Install dependencies if not already installed\n",
    "# !pip install streamlit plotly pandas ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "    \n",
    "# -----------------------------\n",
    "# Complete Daily-Aggregated Dashboard with Alerts\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(sheet_url, parse_dates=[\"observationStart\",\"observationEnd\"])\n",
    "df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "df['date'] = df['observationStart'].dt.date\n",
    "\n",
    "# Columns\n",
    "vitals_cols = [\"heartRate\",\"spo2\",\"temperature\"]\n",
    "adls_nutrition_cols = [\"stepsTaken\",\"sleepHours\",\"exerciseMinutes\",\"calorieIntake\",\"waterIntakeMl\"]\n",
    "\n",
    "# Convert vitals to numeric (strip units)\n",
    "for col in vitals_cols:\n",
    "    df[col] = df[col].astype(str).str.extract(r\"(\\d+\\.?\\d*)\")[0].astype(float)\n",
    "\n",
    "# Convert ADLs & Nutrition to numeric\n",
    "for col in adls_nutrition_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Daily aggregation\n",
    "vitals_daily = df.groupby(['patientId','date'])[vitals_cols].mean().reset_index()\n",
    "adls_nutrition_daily = df.groupby(['patientId','date'])[adls_nutrition_cols].sum().reset_index()\n",
    "alerts_daily = df.groupby(['patientId','date'])['alerts'].apply(lambda x: \",\".join([a for a in x if pd.notna(a) and a!=\"\"])).reset_index()\n",
    "daily_df = pd.merge(vitals_daily, adls_nutrition_daily, on=['patientId','date'])\n",
    "daily_df = pd.merge(daily_df, alerts_daily, on=['patientId','date'])\n",
    "\n",
    "# Patient selector\n",
    "patient_ids = df['patientId'].unique()\n",
    "patient_selector = widgets.Dropdown(options=patient_ids, description=\"Patient ID:\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_dashboard(change):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        \n",
    "        patient_id = patient_selector.value\n",
    "        patient_data = df[df[\"patientId\"]==patient_id].copy()\n",
    "        daily_data = daily_df[daily_df[\"patientId\"]==patient_id]\n",
    "\n",
    "        # Header\n",
    "        patient = patient_data.iloc[0]\n",
    "        print(f\"Patient ID: {patient['patientId']} | Age: {patient['age']} | Gender: {patient['gender']}\\n\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Vitals Charts with Alerts\n",
    "        # -----------------------------\n",
    "        for col in vitals_cols:\n",
    "            if col in daily_data.columns:\n",
    "                fig = go.Figure()\n",
    "                # Normal daily average line\n",
    "                fig.add_trace(go.Scatter(x=daily_data['date'], y=daily_data[col],\n",
    "                                         mode='lines+markers', name=col,\n",
    "                                         line=dict(color='blue')))\n",
    "                # Highlight alerts\n",
    "                alert_points = daily_data[daily_data['alerts'].str.contains(col.split(' ')[0], na=False)]\n",
    "                if not alert_points.empty:\n",
    "                    fig.add_trace(go.Scatter(x=alert_points['date'], y=alert_points[col],\n",
    "                                             mode='markers', name='Alert',\n",
    "                                             marker=dict(color='red', size=10, symbol='x')))\n",
    "                fig.update_layout(title=f\"{col} Daily Average (with Alerts)\",\n",
    "                                  xaxis_title=\"Date\", yaxis_title=col,\n",
    "                                  template=\"plotly_white\")\n",
    "                fig.show()\n",
    "\n",
    "        # -----------------------------\n",
    "        # ADLs & Lifestyle Charts\n",
    "        # -----------------------------\n",
    "        for col in [\"stepsTaken\",\"sleepHours\",\"exerciseMinutes\"]:\n",
    "            if col in daily_data.columns:\n",
    "                fig = px.line(daily_data, x='date', y=col, markers=True,\n",
    "                              title=f\"{col} Daily Total\", template=\"plotly_white\")\n",
    "                fig.update_layout(xaxis_title=\"Date\", yaxis_title=col)\n",
    "                fig.show()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Nutrition Charts\n",
    "        # -----------------------------\n",
    "        for col in [\"calorieIntake\",\"waterIntakeMl\"]:\n",
    "            if col in daily_data.columns:\n",
    "                fig = px.bar(daily_data, x='date', y=col,\n",
    "                             title=f\"{col} Daily Total\", template=\"plotly_white\")\n",
    "                fig.update_layout(xaxis_title=\"Date\", yaxis_title=col)\n",
    "                fig.show()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Behaviour & Emotions\n",
    "        # -----------------------------\n",
    "        if \"behaviourTags\" in patient_data.columns:\n",
    "            print(\"\\nBehaviour Tags (most recent):\", patient_data[\"behaviourTags\"].iloc[-1])\n",
    "        if \"emotionTags\" in patient_data.columns and patient_data[\"emotionTags\"].notna().any():\n",
    "            emotions = patient_data[[\"date\",\"emotionTags\"]].dropna()\n",
    "            emotions = emotions.assign(emotion=emotions[\"emotionTags\"].str.split(\",\")).explode(\"emotion\")\n",
    "            emotions[\"emotion\"] = emotions[\"emotion\"].str.strip()\n",
    "            emotion_counts = emotions.groupby(\"emotion\").size().reset_index(name=\"count\")\n",
    "            if not emotion_counts.empty:\n",
    "                fig = px.pie(emotion_counts, values=\"count\", names=\"emotion\",\n",
    "                             title=\"Emotion Distribution\", hole=0.4,\n",
    "                             color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "                fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "                fig.show()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Clinical Notes\n",
    "        # -----------------------------\n",
    "        if \"nursingNote\" in patient_data.columns:\n",
    "            print(\"\\nMost Recent Nursing Note:\\n\", patient_data[\"nursingNote\"].iloc[-1])\n",
    "        if \"clinicalSummary\" in patient_data.columns:\n",
    "            print(\"\\nMost Recent AI Clinical Summary:\\n\", patient_data[\"clinicalSummary\"].iloc[-1])\n",
    "        \n",
    "\n",
    "        print(\"\\n--- Feature Correlation Matrix ---\")\n",
    "        numeric_cols = vitals_cols + adls_nutrition_cols\n",
    "        correlation_matrix = daily_data[numeric_cols].corr()\n",
    "        fig_corr = px.imshow(\n",
    "            correlation_matrix,\n",
    "            text_auto=True,\n",
    "            aspect=\"auto\",\n",
    "            color_continuous_scale=px.colors.diverging.RdBu,\n",
    "            title=\"Daily Feature Correlation Matrix\"\n",
    "        )\n",
    "        fig_corr.update_layout(\n",
    "            xaxis_nticks=len(numeric_cols),\n",
    "            yaxis_nticks=len(numeric_cols),\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        fig_corr.show()\n",
    "\n",
    "# Link dropdown\n",
    "patient_selector.observe(update_dashboard, names=\"value\")\n",
    "display(patient_selector, output)\n",
    "update_dashboard(None)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Load the highly correlated patient data\n",
    "df = pd.read_csv(sheet_url, parse_dates=[\"observationStart\"])\n",
    "\n",
    "# List of numerical features for the model\n",
    "features = [\"heartRate\", \"spo2\", \"temperature\", \"stepsTaken\", \"sleepHours\", \"exerciseMinutes\"]\n",
    "\n",
    "# Convert vitals to numeric\n",
    "for col in [\"heartRate\", \"spo2\", \"temperature\"]:\n",
    "    df[col] = df[col].astype(str).str.extract(r\"(\\d+\\.?\\d*)\")[0].astype(float)\n",
    "\n",
    "\n",
    "# Dictionary to hold the Isolation Forest model and scaler for each patient\n",
    "patient_models = {}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Loop through each patient to train their unique model\n",
    "# ----------------------------------------------------\n",
    "for patient_id in df['patientId'].unique():\n",
    "    print(f\"\\n--- Building Anomaly Detection Profile for {patient_id} ---\")\n",
    "    patient_data = df[df['patientId'] == patient_id].copy()\n",
    "    \n",
    "    # Select and scale the features\n",
    "    X = patient_data[features]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize and train the Isolation Forest model\n",
    "    # 'contamination' is the expected proportion of anomalies in the dataset.\n",
    "    # We set it to 0.05, assuming 5% of the data points are abnormal.\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    patient_data['anomaly_score'] = iso_forest.fit_predict(X_scaled)\n",
    "    \n",
    "    # Store the model and scaler for later use\n",
    "    patient_models[patient_id] = {\n",
    "        'data': patient_data,\n",
    "        'scaler': scaler,\n",
    "        'isolation_forest': iso_forest\n",
    "    }\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # Visualization and Analysis for the current patient\n",
    "    # ----------------------------------------------------\n",
    "    print(\"Visualizing Anomaly Detection Results:\")\n",
    "    \n",
    "    # Identify the anomalies\n",
    "    anomalies = patient_data[patient_data['anomaly_score'] == -1]\n",
    "    \n",
    "    # Plot Heart Rate with anomalies highlighted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(patient_data['observationStart'], patient_data['heartRate'], label='Heart Rate', color='blue')\n",
    "    plt.scatter(anomalies['observationStart'], anomalies['heartRate'], color='red', s=100, label='Anomaly', marker='x')\n",
    "    plt.title(f'{patient_id} Heart Rate with Detected Anomalies')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Heart Rate (bpm)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Steps Taken with anomalies highlighted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(patient_data['observationStart'], patient_data['stepsTaken'], label='Steps Taken', color='green')\n",
    "    plt.scatter(anomalies['observationStart'], anomalies['stepsTaken'], color='red', s=100, label='Anomaly', marker='x')\n",
    "    plt.title(f'{patient_id} Steps Taken with Detected Anomalies')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Steps Taken')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Print a summary of a few detected anomalies to demonstrate the model's output\n",
    "    print(\"\\n--- Summary of First 5 Detected Anomalies ---\")\n",
    "    if not anomalies.empty:\n",
    "        print(anomalies[['observationStart', 'heartRate', 'stepsTaken', 'sleepHours', 'alerts']].head())\n",
    "    else:\n",
    "        print(\"No anomalies were detected based on the current contamination setting.\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv(sheet_url, parse_dates=[\"observationStart\"])\n",
    "\n",
    "# --- FIX 1: Ensure patientId is a string type to avoid mixing with numeric comparisons ---\n",
    "df['patientId'] = df['patientId'].astype(str)\n",
    "\n",
    "# List of numerical features that might be objects\n",
    "vitals_cols = [\"heartRate\", \"spo2\", \"temperature\", \"bloodPressure\"]\n",
    "adls_nutrition_cols = [\"stepsTaken\", \"sleepHours\", \"exerciseMinutes\", \"calorieIntake\", \"waterIntakeMl\"]\n",
    "\n",
    "# --- CRUCIAL FIX 2: Ensure all columns are numeric before aggregation ---\n",
    "for col in vitals_cols + adls_nutrition_cols:\n",
    "    # Use .str.extract() to get the numeric part from strings, then convert to float\n",
    "    df[col] = df[col].astype(str).str.extract(r'(\\d+\\.?\\d*)', expand=False)\n",
    "    \n",
    "    # Coerce any remaining non-numeric values to NaN and convert to float\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Aggregate data to a daily level\n",
    "daily_df = df.groupby(['patientId', df['observationStart'].dt.date]).agg(\n",
    "    heartRate=('heartRate', 'mean'),\n",
    "    spo2=('spo2', 'mean'),\n",
    "    temperature=('temperature', 'mean'),\n",
    "    stepsTaken=('stepsTaken', 'sum'),\n",
    "    sleepHours=('sleepHours', 'sum'),\n",
    "    exerciseMinutes=('exerciseMinutes', 'sum'),\n",
    "    calorieIntake=('calorieIntake', 'sum'),\n",
    "    waterIntakeMl=('waterIntakeMl', 'sum'),\n",
    "    state=('state', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# --- FIX 3: Fill any NaN values that may have been created during aggregation ---\n",
    "# This prevents errors during the train_test_split.\n",
    "daily_df.fillna(0, inplace=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Feature Engineering and Encoding\n",
    "# ----------------------------------------\n",
    "# Define features and target\n",
    "features = ['heartRate', 'spo2', 'temperature', 'stepsTaken', 'sleepHours', 'exerciseMinutes', 'calorieIntake', 'waterIntakeMl', 'patientId']\n",
    "target = 'state'\n",
    "\n",
    "X = daily_df[features]\n",
    "y = daily_df[target]\n",
    "\n",
    "# One-hot encode the 'patientId' to make it a usable feature for the model\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "patient_id_encoded = encoder.fit_transform(X[['patientId']]).toarray()\n",
    "patient_id_df = pd.DataFrame(patient_id_encoded, columns=encoder.get_feature_names_out(['patientId']))\n",
    "\n",
    "# Combine numerical features with the encoded patient ID\n",
    "X_numerical = X.drop('patientId', axis=1)\n",
    "X_combined = pd.concat([X_numerical, patient_id_df], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Data successfully cleaned, aggregated, and split for training.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
