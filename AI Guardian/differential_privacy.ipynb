{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differential Privacy for Data Anonymization\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DifferentialPrivacy:\n",
    "    def _init_(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def add_noise(self, data):\n",
    "        noise = np.random.laplace(0, 1 / self.epsilon, size=data.shape)\n",
    "        return data + noise\n",
    "\n",
    "# Example Usage\n",
    "if _name_ == \"_main_\":\n",
    "    dp = DifferentialPrivacy(epsilon=0.5)\n",
    "    sensitive_data = np.array([100, 200, 300])  # Example data\n",
    "    anonymized_data = dp.add_noise(sensitive_data)\n",
    "    print(\"Anonymized Data:\", anonymized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOMALY DETECTION\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Generate Simulated WiFi CSI Data (or load real data)\n",
    "# Normal data (e.g., typical CSI measurements)\n",
    "normal_data = np.random.normal(loc=50, scale=10, size=(100, 2))\n",
    "\n",
    "# Anomalous data (e.g., CSI changes caused by an adversarial attack)\n",
    "anomalous_data = np.random.uniform(low=100, high=150, size=(10, 2))\n",
    "\n",
    "# Combine data\n",
    "data = np.vstack((normal_data, anomalous_data))\n",
    "labels = np.array([0] * 100 + [1] * 10)  # 0 = normal, 1 = anomaly\n",
    "\n",
    "# Step 2: Train the Anomaly Detection Model\n",
    "# Initialize Isolation Forest\n",
    "model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "model.fit(data)\n",
    "\n",
    "# Step 3: Predict Anomalies\n",
    "# Predict anomaly scores (-1 indicates anomaly)\n",
    "predictions = model.predict(data)\n",
    "anomaly_scores = model.decision_function(data)\n",
    "\n",
    "# Step 4: Evaluate Results\n",
    "print(\"Predictions:\", predictions)  # -1 = anomaly, 1 = normal\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0], data[:, 1], c=predictions, cmap='coolwarm', label=\"Predictions\")\n",
    "plt.scatter(anomalous_data[:, 0], anomalous_data[:, 1], c='red', marker='x', label=\"True Anomalies\")\n",
    "plt.title(\"Anomaly Detection in WiFi CSI Data\")\n",
    "plt.xlabel(\"Feature 1 (e.g., CSI amplitude)\")\n",
    "plt.ylabel(\"Feature 2 (e.g., CSI phase)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Save Model for Integration\n",
    "import joblib\n",
    "joblib.dump(model, \"anomaly_detection_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encryption for Data Transmission\n",
    "\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Generate a key\n",
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Encrypt data\n",
    "data = b\"Sensitive WiFi CSI Data\"\n",
    "encrypted_data = cipher_suite.encrypt(data)\n",
    "\n",
    "# Decrypt data\n",
    "decrypted_data = cipher_suite.decrypt(encrypted_data)\n",
    "print(\"Decrypted Data:\", decrypted_data.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06091fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cases for Differential Privacy\n",
    "\n",
    "import numpy as np\n",
    "from differential_privacy import DifferentialPrivacy  # Assuming the DifferentialPrivacy class is in a module named differential_privacy.\n",
    "\n",
    "def test_differential_privacy():\n",
    "    dp = DifferentialPrivacy(epsilon=1.0)\n",
    "    sensitive_data = np.array([100, 200, 300])\n",
    "    \n",
    "    # Add noise to the data\n",
    "    anonymized_data = dp.add_noise(sensitive_data)\n",
    "    \n",
    "    # Test 1: Check if noise is added\n",
    "    assert not np.array_equal(sensitive_data, anonymized_data), \"Noise not added to the data\"\n",
    "    \n",
    "    # Test 2: Ensure the length of the data remains the same\n",
    "    assert len(sensitive_data) == len(anonymized_data), \"Length mismatch after adding noise\"\n",
    "    \n",
    "    print(\"Differential Privacy tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_differential_privacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ef649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cases for Encryption\n",
    "\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def test_encryption():\n",
    "    # Generate encryption key\n",
    "    key = Fernet.generate_key()\n",
    "    cipher_suite = Fernet(key)\n",
    "    \n",
    "    data = b\"Sensitive WiFi CSI Data\"\n",
    "    \n",
    "    # Encrypt data\n",
    "    encrypted_data = cipher_suite.encrypt(data)\n",
    "    \n",
    "    # Test 1: Ensure encryption produces a different output\n",
    "    assert data != encrypted_data, \"Data was not encrypted properly\"\n",
    "    \n",
    "    # Decrypt data\n",
    "    decrypted_data = cipher_suite.decrypt(encrypted_data)\n",
    "    \n",
    "    # Test 2: Ensure decryption restores the original data\n",
    "    assert data == decrypted_data, \"Decrypted data does not match the original\"\n",
    "    \n",
    "    print(\"Encryption tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_encryption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cases for Anomaly Detection\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "def test_anomaly_detection():\n",
    "    # Generate simulated data\n",
    "    normal_data = np.random.normal(loc=50, scale=10, size=(100, 2))\n",
    "    anomalous_data = np.random.uniform(low=100, high=150, size=(10, 2))\n",
    "    data = np.vstack((normal_data, anomalous_data))\n",
    "    \n",
    "    # Train the Isolation Forest model\n",
    "    model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "    model.fit(data)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    predictions = model.predict(data)  # -1 = anomaly, 1 = normal\n",
    "    \n",
    "    # Test 1: Ensure model detects anomalies\n",
    "    assert -1 in predictions, \"Model failed to detect anomalies\"\n",
    "    \n",
    "    # Test 2: Ensure normal data is detected as non-anomalous\n",
    "    normal_predictions = predictions[:100]\n",
    "    assert all(pred == 1 for pred in normal_predictions), \"Normal data incorrectly labeled as anomaly\"\n",
    "    \n",
    "    # Test 3: Ensure anomalous data is detected as anomalies\n",
    "    anomaly_predictions = predictions[100:]\n",
    "    assert all(pred == -1 for pred in anomaly_predictions), \"Anomalous data incorrectly labeled as normal\"\n",
    "    \n",
    "    print(\"Anomaly Detection tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_anomaly_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
